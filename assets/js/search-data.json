{
  
    
        "post0": {
            "title": "Steps On GANs",
            "content": ". Image credit: Dev Nag . This post is not necessarily a crash course on GANs. It is at least a record of me giving myself a crash course on GANs. Adding to this as I go. . Intro/Motivation . I’ve been wanting to grasp the seeming-magic of Generative Adversarial Networks (GANs) since I started seeing handbags turned into shoes and brunettes turned to blondes… …and seeing Magic Pony’s image super-resolution results and hearing that Yann Lecun had called GANs the most important innovation in machine learning in recent years. . Finally, seeing Google’s Cat-Pig Sketch-Drawing Math… . …broke me, and so…I need to ‘get’ this. . I’ve noticed that, although people use GANs with great success for images, not many have tried using them for audio yet (Note: see SEGAN paper, below). Maybe with already-successful generative audio systems like WaveNet, SampleRNN (listen to those piano sounds!!) and TacoTron there’s less of a push for trying GANs. Or maybe GANs just suck for audio. Guess I’ll find out… . Steps I Took . Day 1: . Gathered list of some prominent papers (below). | Watched video of Ian Goodfellow’s Berkeley lecture (notes below). | Started reading the EBGAN paper (notes below)… | …but soon switched to BEGAN paper – because wow! Look at these generated images: | Googled for Keras-based BEGAN implementations and other code repositories (below)…Noticed SEGAN… | …Kept reading BEGAN, making notes as I went (below). | Finished paper, started looking through BEGAN codes from GitHub (below) &amp; began trying them out… a. Cloned @mokemokechicken’s Keras repo, grabbed suggested LFW database, converted images via script, ran training… Takes 140 seconds per epoch on Titan X Pascal. . Main part of code is in models.py | . b. Cloned @carpedm’s Tensorflow repo, looked through it, got CelebA dataset, started running code. . | Leaving codes to train overnight. Next time, I’d like to try to better understand the use of an autoencoder as the discriminator. | Day 2: . My office is hot. Two Titan X GPUs pulling ~230W for 10 hours straight has put the cards up towards annoyingly high temperatures, as in ~ 85 Celsius! My previous nightly runs wouldn’t even go above 60 C. But the results – espically from the straight-Tensorflow code trained on the CelebA dataset – are as incredible as advertised! (Not that I understand them yet. LOL.) The Keras version, despite claiming to be a BEGAN implementation, seems to suffer from “mode collapse,” i.e. that too many very similar images get generated. | Fished around a little more on the web for audio GAN applications. Found an RNN-GAN application to MIDI, and found actual audio examples of what not to do: don’t try to just produce spectrograms with DCGAN and convert them to audio. The latter authors seem to have decided to switch to a SampleRNN approach. Perhaps it would be wise to heed their example? ;-) | Since EBGAN implemented autoencoders as discriminators before BEGAN did, I went back to read that part of the EBGAN paper. Indeed, section “2.3 - Using AutoEncoders” (page 4). (see notes below) | Ok, I basically get the autoencoder-discriminator thing now. :-) | Day 3: . “Life” intervened. :-/ Hope to pick this up later. . Papers . Haven’t read hardly any of these yet, just gathering them here for reference: . Original GAN Paper: ” Generative Adversarial Networks” by GoodFellow (2014) | DCGAN: “Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks” by Radford, Metz &amp; Chintala (2015) | “Image-to-Image Translation with Conditional Adversarial Networks” by Isola et al (2016) | “Improved Techniques for Training GANs” by Salimans et al (2016). | DiscoGAN: “Learning to Discover Cross-Domain Relations with Generative Adversarial Networks” by Kim et al. (2017) | EBGAN: “Energy-based Generative Adversarial Network by Zhao, Matheiu &amp; Lecun (2016/2017). Remarks/Notes: | “This variant [EBGAN] converges more stably [than previous GANs] and is both easy to train and robust to hyper-parameter variations” (quoting from BEGAN paper, below). | If it’s energy-based, does that mean we get a Lagrangian, and Euler-Lagrange Equations, and Lagrange Multipliers? And thus can physics students (&amp; professors!) grasp these networks in a straightforward way? Should perhaps take a look at Lecun’s Tutorial on Energy-Based Learning. | “The energy is the resconstruction error [of the autoencoder]” (Section 1.3, bullet points) | | . Image credit: Roozbeh Farhoodi + EBGAN authors . “…256×256 pixel resolution, without a multi-scale approach.” (ibid) | Section 2.3 covers on the use of the autoencoder as a discriminator. Wow, truly, the discriminator’s “energy”/ “loss” criterion is literally just the reconstruction error of the autoencoder. How does that get you a discriminator?? | It gets you a discriminator because the outputs of the generator are likely to have high energies whereas the real data (supposedly) will produce low energies: “We argue that the energy function (the discriminator) in the EBGAN framework is also seen as being regularized by having a generator producing the contrastive samples, to which the discrim- inator ought to give high reconstruction energies” (bottom of page 4). | . | “Wasserstein GAN (WGAN) by Arjovsky, Chintala, &amp; Bottou (2017) . | “BEGAN: Boundary Equilibrium Generative Adversarial Networks” by Berthelot, Schumm &amp; Metz (April 2017). . Remarks/Notes: | “Our model is easier to train and simpler than other GANs architectures: no batch normalization, no dropout, no transpose convolutions and no exponential growth for convolution filters.” (end of section 3.5, page 5) | This is probably not the kind of paper that anyone off the street can just pick up &amp; read. There will be math. | Uses an autoencoder for the discriminator. | I notice that Table 1, page 8 shows “DFM” (from “Improving Generative Adversarial Networks with Denoising Feature Matching” by Warde-Farley &amp; Bengio, 2017) as scoring higher than BEGAN. | page 2: “Given two normal distributions…with covariances C1,C2C_1, C_2C1​,C2​,…”: see “Multivariate Normal Distribution”. | Section 3.3, Equilibrium: The “E[ ] mathbb{E}[ ]E[ ]” notation – as in E[L(x)] mathbb{E} left[ mathcal{L}(x) right]E[L(x)] – means “expected value.” See https://en.wikipedia.org/wiki/Expected_value | Introduces the diversity ratio: γ=E[L(G(z))]E[L(x)] gamma= frac{ mathbb{E} left[ mathcal{L}(G(z)) right]}{ mathbb{E} left[ mathcal{L}(x) right]}γ=E[L(x)]E[L(G(z))]​. “Lower values of γ gammaγ lead to lower image diversity because the discriminator focuses more heavily on auto-encoding real images.” | “3.5 Model architecture”: Did not actually get the bit about the autoencoder as the discriminator: “How does an autoencoder output a 1 or a zero?” | Ok, done. Will come back later if needed; maybe looking at code will make things clearer… | . | “SEGAN: Speech Enhancement Generative Adversarial Network” by Pascual, Bonafonte &amp; Serra (April 2017). Actual audio GAN! They only used it to remove noise. | . Videos . Ian Goodfellow (original GAN author), Guest lecture on GANs for UC Berkeley CS295 (Oct 2016). 1 hour 27 minutes. NOTE: actually starts at 4:33. Watch at 1.25 speed. Remarks/Notes: | This is on a fairly “high” level, which may be too much for some viewers; if hearing the words “probability distribution” over &amp; over again makes you tune out, and e.g. if you don’t know what a Jacobian is, then you may not want to watch this. | His “Taxonomy of Generative Models” is GREAT! | The discriminator is just an ordinary classifier. | So, the generator’s cost function can be just the negative of the discriminator’s cost function, (i.e. it tries to “mess up” the discriminator), however that can saturate (i.e. produce small gradients) so instead they try to “maximize the probability that the discriminator will make a mistake” (44:12). | “KL divergence” is a measure of the ‘difference’ between two PD’s. | “Logit” is the inverse of the sigmoid/logistical function. (logit&lt;–&gt;sigmoid :: tan&lt;–&gt;arctan) | Jensen-Shannon divergence is a measure of the ‘similarity’ between two PD’s. Jensen-Shannon produces better results for GANs than KL/maximum likelihood. | . | . Web Posts/Tutorials . “Machine Learning is Fun Part 7: Abusing Generative Adversarial Networks to Make 8-bit Pixel Art” by Adam Geitgey, skip down to “How DCGANs Work” (2017) | Post on BEGAN: https://blog.heuritech.com/2017/04/11/began-state-of-the-art-generation-of-faces-with-generative-adversarial-networks/ | An introduction to Generative Adversarial Networks (with code in TensorFlow) | “Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)” by Dev Nag (2017) | “Stability of Generative Adversarial Networks” by Nicholas Guttenberg (2016) | “End to End Neural Art with Generative Models” by Bing Xu (2016) . | Kording Lab GAN Tutorial by Roozbeh Farhoodi :-). Nicely done, has code too. . | . Code . Keras: . ‘Basic’ GAN with MNIST example: https://www.kdnuggets.com/2016/07/mnist-generative-adversarial-model-keras.html | GAN, BiGAN &amp; Adversarial AutoEncoder: https://github.com/bstriner/keras-adversarial | Kording Lab’s GAN tutorial, Jupyter Notebook https://github.com/KordingLab/lab_teaching_2016/blob/master/session_4/Generative%20Adversarial%20Networks.ipynb. (Code is short and understandable.) | Keras BEGAN: https://github.com/mokemokechicken/keras_BEGAN: Only works on 64x64 images; BEGAN paper shows some 128x128 | https://github.com/pbontrager/BEGAN-keras: No documentation, and I don’t see how it could run. I notice local variables being referenced in models.py as if they’re global. | . | Keras DCGAN (MNIST): https://github.com/jacobgil/keras-dcgan | Auxiliary Classifier GAN: https://github.com/lukedeo/keras-acgan | . Tensorflow: . BEGAN-Tensorflow: https://github.com/carpedm20/BEGAN-tensorflow | EBGAN.Tensorflow: https://github.com/shekkizh/EBGAN.tensorflow | SEGAN: https://github.com/santi-pdp/segan | DCGAN-Tensorflow: https://github.com/carpedm20/DCGAN-tensorflow | . PyTorch: . Tutorial &amp; simple implementation: https://github.com/devnag/pytorch-generative-adversarial-networks | . Datasets . CelebA: https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html | MNIST: https://yann.lecun.com/exdb/mnist/ | Speech enhancement: https://datashare.is.ed.ac.uk/handle/10283/1942 | “Labelled Faces in the Wild” https://vis-www.cs.umass.edu/lfw/ | . More References (Lists) . “Delving deep into Generative Adversarial Networks (GANs): A curated list of state-of-the-art publications and resources about Generative Adversarial Networks (GANs) and their applications.” | .",
            "url": "https://dnlam.github.io/fastblog/2022/03/15/GAN.html",
            "relUrl": "/2022/03/15/GAN.html",
            "date": " • Mar 15, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "The Beauty of Neural Network",
            "content": "The Sample Problem . Consider a system that tries to map groups of 3 inputs to some corresponding output which is a single number. In the following picture, we&#39;ll show each set of 3 inputs as a row of a matrix $X$, and each output as the corresponding row of $Y$: . $$ overbrace{ left[ { begin{array}{ccc} 0 &amp; 0 &amp; 1 0 &amp; 1 &amp; 1 1 &amp; 0 &amp; 1 1 &amp; 1 &amp; 1 end{array} } right] }^{X} rightarrow overbrace{ left[ { begin{array}{c} 0 0 1 1 end{array} } right] }^Y. $$Even though this system has an exact solution (namely, $Y$ equals the first column of $X$), usually we&#39;ll need to be satisfied with a system that maps our inputs $X$ to some approximate &quot;prediction&quot; $ tilde{Y}$, which we hope to bring closer to the &quot;target&quot; $Y$ by means of successive improvements. . The way we&#39;ll get our prediction $ tilde{Y}$ is by means of a weighted sum of each set of 3 inputs, and some nonlinear function $f$ which we call the &quot;activation function&quot; (or just &quot;activation&quot;). Pictorially, the process looks like the following, for each row $i$ of $X$ and $Y$, (where the columns of $X$ are shown arranged vertically instead of horizonally): . . In terms of matrix multiplication, since X is a 4x3 matrix, and Y is a 4x1 matrix, that implies that our weights should be a 3x1 matrix consisting of (unknown) values $w_0$, $w_1$ and $w_2$. The calculation can be written as: . $$ f left( overbrace{ left[ { begin{array}{ccc} 0 &amp; 0 &amp; 1 0 &amp; 1 &amp; 1 1 &amp; 0 &amp; 1 1 &amp; 1 &amp; 1 end{array} } right] }^ text{X} overbrace{ left[ { begin{array}{c} w_0 w_1 w_2 end{array} } right] }^{w} right) = overbrace{ left[ { begin{array}{c} 0 0 1 1 end{array} } right] }^{ tilde{Y}} $$Our nonlinear activation function $f$ is taken to operate on each row element one at a time, and we&#39;ll let $f_i$ denote the $i$th row of this completed activation, i.e.: . $$ f_i = f left( sum_j X_{ij}w_j right) = tilde{Y}_i . $$The particular activation function we will use is the &quot;sigmoid&quot;, . $$ f(x) = {1 over{1+e^{-x}}}, $$-- click here to see a plot of this function -- which has the derivative . $$ {df over dx} = {e^{-x} over(1 + e^{-x})^2} $$which can be shown (Hint: exercise for &quot;mathy&quot; students!) to simplify to $$ {df over dx}= f(1-f). $$ . The overall problem then amounts to finding the values of the &quot;weights&quot; $w_0, w_1,$ and $w_2$ so that the $ tilde{Y}$ we calculate is as close to the target $Y$ as possible. . To do this, we will seek to minimize a loss function defined as a sum across all data points we have, i.e. all 4 rows. The loss function $L$ we will choose is the mean square error loss, or MSE, we will use a &#39;better&#39; loss function for this problem): . $$ L = {1 over N} sum_{i=0}^{N-1} left[ tilde{Y}_i - Y_i right]^2, $$or in terms of the activation function $$ L = {1 over N} sum_{i=0}^{N-1} left[ f_i - Y_i right]^2. $$ . Each of the weights $w_j$ ($j=0..2$) will start with random values, and then be updated via gradient descent, i.e. . $$ w_j^{new} = w_j^{old} - alpha{ partial L over partial w_j} $$where $ alpha$ is the learning rate, chosen to be some small parameter. For the MSE loss shown above, the partial derivatives with respect to each of the weights is . $$ { partial L over partial w_j} = {2 over N} sum_{i=0}^{N-1} left[ tilde{Y}_i - Y_i right]{ partial f_i over partial w_j} = {2 over N} sum_{i=0}^{N-1} left[ tilde{Y}_i - Y_i right]f_i(1-f_i)X_{ij}. $$Absorbing the factor of 2/N into our choice of $ alpha$, and writing the summation as a dot product, and noting that $f_i = tilde{Y}_i$, we can write the update for all the weights together as . $$ w = w - alpha X^T cdot left( [ tilde{Y}-Y]* tilde{Y}*(1- tilde{Y}) right) $$where the $ cdot$ denotes a matrix-matrix product (i.e. a dot product for successive rows of $X^T$) and $*$ denotes elementwise multiplication. . To clarify the above expression in terms of matrix dimensions, we can see that $w$, a 3x1 matrix, can be made by multipyting $X^T$ (a 3 x4 matrix) with the term in parentheses, i.e. the product of elementwise terms involving $ tilde{Y}$, which is a 4x1 matrix. In other words, a 3x4 matrix, times a 4x1 matrix, yields a 3x1 matrix. . Actual Code . The full code for all of this is then... . # https://iamtrask.github.io/2015/07/12/basic-python-network/ import numpy as np # sigmoid activation def sigmoid(x,deriv=False): if(deriv==True): return x*(1-x) return 1/(1+np.exp(-x)) # input dataset X = np.array([ [0,0,1], [0,1,1], [1,0,1], [1,1,1] ]) # target output dataset Y = np.array([[0,0,1,1]]).T # seed random numbers to make calculation # deterministic (just a good practice) np.random.seed(1) # initialize weights randomly with mean 0 w = 2*np.random.random((3,1)) - 1 alpha = 1.0 # learning rate loss_history = [] # keep a record of how the loss proceeded, blank for now for iter in range(1000): # forward propagation Y_pred = sigmoid(np.dot(X,w)) # prediction, i.e. tilde{Y} # how much did we miss? diff = Y_pred - Y loss_history.append((diff**2).mean()) # add to the history of the loss # update weights w -= alpha * np.dot( X.T, diff*sigmoid(Y_pred, deriv=True)) print(&quot;Output After Training:&quot;) print(&quot;Y_pred = (should be two 0&#39;s followed by two 1&#39;s) n&quot;,Y_pred) print(&quot;weights = n&quot;,w) . Output After Training: Y_pred = (should be two 0&#39;s followed by two 1&#39;s) [[0.03178421] [0.02576499] [0.97906682] [0.97414645]] weights = [[ 7.26283009] [-0.21614618] [-3.41703015]] . Note that, because of our nonlinear activation, we don&#39;t get the solution $w_0=1, w_1=0, w_2=0$. . Plotting the loss vs. iteration number, we see... . %matplotlib inline import matplotlib.pyplot as plt plt.loglog(loss_history) plt.xlabel(&quot;Iteration&quot;) plt.ylabel(&quot;Loss&quot;) plt.show() . Change the activation function . Another popular choice of activation function is the rectified linear unit or ReLU. The function ReLU(x) is zero for x &lt;= 0, and equal to x (i.e. a straight line at 45 degrees for) x &gt;0. It can be written as max(x,0) or x * (x&gt;0), and its derivative is 1 for positive x, and zero otherwise. . Click here to see a graph of ReLU . Modifying our earlier code to use ReLU activation instead of sigmoid looks like this: . def relu(x,deriv=False): # relu activation if(deriv==True): return 1*(x&gt;0) return x*(x&gt;0) # seed random numbers to make calculation # deterministic (just a good practice) np.random.seed(1) # initialize weights randomly (but only &gt;0 because ReLU clips otherwise) w = np.random.random((3,1)) alpha = 0.3 # learning rate new_loss_history = [] # keep a record of how the error proceeded for iter in range(1000): # forward propagation Y_pred = relu(np.dot(X,w)) # how much did we miss? diff = Y_pred - Y new_loss_history.append((diff**2).mean()) # add to the record of the loss # update weights w -= alpha * np.dot( X.T, diff*relu(Y_pred, deriv=True)) print(&quot;Output After Training:&quot;) print(&quot;Y_pred = (should be two 0&#39;s followed by two 1&#39;s) n&quot;,Y_pred) print(&quot;weights = n&quot;,w) . Output After Training: Y_pred = (should be two 0&#39;s followed by two 1&#39;s) [[-0.] [-0.] [ 1.] [ 1.]] weights = [[ 1.01784368e+00] [ 8.53961786e-17] [-1.78436793e-02]] . print( w[2] - (1-w[0]) ) . [-3.46944695e-17] . Plot old results with new results: . %matplotlib inline import matplotlib.pyplot as plt plt.loglog(loss_history,label=&quot;sigmoid&quot;) plt.loglog(new_loss_history,label=&quot;relu&quot;) plt.xlabel(&quot;Iteration&quot;) plt.ylabel(&quot;Loss&quot;) plt.legend() plt.show() . Looks like ReLU may be a better choice than sigmoid for this problem! . Exercise: Read a 7-segment display . A 7-segment display is used for displaying numerical digits 0 through 9, usually by lighting up LEDs or parts of a liquid crystal display (LCD). The segments are labelled $a$ through $g$ according to the following diagram: . . Diagram of the network . The 7 inputs &quot;a&quot; through &quot;g&quot; will be mapped to 10 outputs for the individual digits, and each output can range from 0 (&quot;false&quot; or &quot;no&quot;) to 1 (&quot;true&quot; or &quot;yes&quot;) for that digit. The input and outputs will be connected by a matrix of weights. Pictorially, this looks like the following (Not shown: activation function $f$): . . ...where again, this network operates on a single data point at a time, datapoints which are rows of X and Y. What is shown in the above diagram are the columns of $X$ and $Y$ for a single row (/ single data point). . Create the dataset . Let the input X be the segments $a$ through $g$ are the columns of the input $X$, and are either 1 for on or 0 for off. Let the columns of the target $Y$ be the digits 0-9 themselves arranged in a &quot;one hot&quot; encoding scheme, as follows: . Digit | One-Hot Encoding for $Y$ | . 0 | 1,0,0,0,0,0,0,0,0,0 | . 1 | 0,1,0,0,0,0,0,0,0,0 | . 2 | 0,0,1,0,0,0,0,0,0,0 | . ... | ... | . 9 | 0,0,0,0,0,0,0,0,0,1 | . The values in the columns for $Y$ are essentially true/false &quot;bits&quot; for each digit, answering the question &quot;Is this digit the appropriate output?&quot; with a &quot;yes&quot;(=1) or &quot;no&quot; (=0) response. . The input $X$ will be a 10x7 matrix, and the target $Y$ will be a 10x10 matrix. Each row of $X$ will be the segments to produce the digit for that row. For example, the zeroth row of $X$ should show segments on which make an image of the digit zero, namely segments a, b, c, d, e, and f but not g, so that the zeroth row of X should be [1,1,1,1,1,1,0]. . Define numpy arrays for both $X$ and $Y$ (Hint: for $Y$, check out np.eye()): . # for the 7-segment display. The following is just a &quot;stub&quot; to get you started. X = np.array([ [1,1,1,1,1,1,0], [], [], [] ]) Y = np.array([ [1,0,0,0,0,0,0,0,0,0], [], [] ]) . Initialize the weights . Previously the dimensions of the weight matrix $w$ were 3x1 because we were mapping each row of 3 elements in $X$ to each row of 1 element of $Y$. For this new problem, each row of $X$ has 7 elements, and we want to map those to the 10 elements in each 1-hot-encoded row of $Y$, so what should the dimensions of the weights matrix $w$ be? . Write some numpy code to randomly initialize the weights matrix: . np.random.seed(1) # initial RNG so everybody gets similar results w = np.random.random(( , )) # Students, fill in the array dimensions here . File &#34;&lt;ipython-input-7-20f53a51cded&gt;&#34;, line 1 w = np.random.random(( , )) ^ SyntaxError: invalid syntax . Train the network . Having created an $X$ and its matching $Y$, and initalized the weights $w$ randomly, train a neural network such as the ones above to learn to map a row of X to a row of Y, i.e. train it to recognize digits on 7-segment displays. Do this below. . # Use sigmoid activation, and 1000 iterations, and learning rate of 0.9 # Question: What happens if you use ReLU instead? Try it later. Is ReLU always the best choice? # And then print out your Y_pred &amp; weights matrix, and limit it to 3 significant digits print(&quot;Output After Training:&quot;) np.set_printoptions(formatter={&#39;float&#39;: lambda x: &quot;{0:0.3f}&quot;.format(x)}) # 3 sig figs print(&quot;Y_pred= n&quot;,Y_pred) print(&quot;weights = n&quot;,repr(w)) # the repr() makes it so it can be copied &amp; pasted back into Python code . Final Check: Keras version . Keras is a neural network library that lets us write NN applications very compactly. Try running the following using the X and Y from your 7-segment dataset: . import keras from keras.models import Sequential from keras.layers import Dense, Activation model = Sequential([ Dense(10, input_shape=(7,)), Activation(&#39;sigmoid&#39;) ]) model.compile(optimizer=&#39;adam&#39;, # We&#39;ll talk about optimizer choices and loss choices later loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(X, Y, epochs=200, batch_size=1) print(&quot; nY_tilde = n&quot;, model.predict(X) ) . Follow-up: Remarks . Re-stating what we just did . The original problem (posed at the top of this notebook) involves mapping some points from a 3-dimensional space into points in a 1-dimensional space, i.e. to points on the number line. The mapping is done by the combination of a weighted sum (a linear operation) and a nonlinear &quot;activation function&quot; applied to that sum. The use of an activation function like a sigmoid was originally intended to serve as an analogy of activation of biological neurons. Nonlinear activation functions are source of the &quot;power&quot; of neural networks (essentially we approximate some other function by means of a sum of basis functions in some function space, but don&#39;t worry about that if you&#39;re not math-inclined). The algorithm &#39;learns&#39; to approximate this operation via supervised learning and gradient descent according to some loss function. We used the mean squared error (MSE) for our loss, but lots and lots of different loss functions could be used, a few of which we&#39;ll look at another time. . Question for reflection: Unlike fitting a line $y = mx+b$, the weighted sum in our models in this notebook had no constant &quot;bias&quot; term like $b$. How might we include such a term? . One thing we glossed over: &quot;batch size&quot; . Question: Should we apply the gradient descent &quot;update&quot; to the weights each time we process a single row of $X$ &amp; $Y$, or should we compute the combined loss of all the rows together at the same time, and then do the update? This is essentially asking the same question as &quot;When fitting a line $mx+b$ to a bunch of data points, should we use all the points together to update $m$ and $b,$ or should we do this one point at a time -- compute the gradients of the loss at one point, update the weights, compute gradients at another point, etc.?&quot; . The number of points you use is called the batch size and it is what&#39;s known as a &quot;hyperparameter&quot; -- it is not part of the model per se, but it is a(n important) choice you make when training the model. The batch size affects the learning as follows: Averaging the gradints for many data points (i..e. a large batch size) will produce a smoother loss function and will also usually make the code execute more quickly through the dataset, but updating the weights for every point will cause the algorithm to learn with fewer iterations. . One quick way to observe this is to go up to the Keras code above and change batch_size from 1 to 10, and re-execute the cell. How is the accuracy after 200 iteractions, compared to when batch_size=1? . Terminology: Technically, it&#39;s called &quot;batch training&quot; when you sum the gradients for all the data points before updating the weights, whereas using fewer points is &quot;minibatch training&quot;, and updating for each point (i.e. each row, for us) is Stochastic Gradient Descent* (SGD -- more on these terms here). In practice, there is a tradeoff between smaller vs. larger (mini)batches, which has been the subject of intense scrutiny by researchers over the years. We will have more to say on this later. . For discussion later: In our presentation above, were we using batch training, minibatch training or SGD? . . . *Note: many people will regard SGD as an optimization algorithm per se, and refer to doing SGD even for (mini)batch sizes larger than 1. . Optional: If you want to go really crazy . How about training on this dataset: $$ overbrace{ left[ { begin{array}{cc} 0 &amp; 0 0 &amp; 1 1 &amp; 0 1 &amp; 1 end{array} } right] }^{X} rightarrow overbrace{ left[ { begin{array}{c} 0 1 1 0 end{array} } right] }^Y. $$ Good luck! ;-) (Hint 1: This problem features prominently in the history of Neural Networks, involving Marvin Minsky and &quot;AI Winter.&quot; Hint 2: This whole lesson could instead be entitled &quot;My First Artificial Neuron.&quot;) . Additional Optional Exercise: Binary Math vs. One-Hot Encoding . For the 7-segment display, we used a one-hot encoding for our output, namely a set of true/false &quot;bits&quot; for each digit. One may wonder how effective this ouput-encoding method is, compared to a different bit-setting encoding method, namely binary representations. . Construct the target output matrix $Y$ for binary representations of the numbers 0 through 9. Your target matrix should have 10 rows and 4 columns (i.e, output bits for 1s, 2s, 4s, and 8s). | Using this $Y$ array, train the network as before, and plot the loss as a function of iteration. | Question: Which method works &#39;better&#39;? One-hot encoding or binary encoding? .",
            "url": "https://dnlam.github.io/fastblog/2022/03/14/_The_Beauty_Of_Neural_Network.html",
            "relUrl": "/2022/03/14/_The_Beauty_Of_Neural_Network.html",
            "date": " • Mar 14, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "MoonShot Technologies",
            "content": "Congratulations! Due to your strong performance in the first three courses, you landed a job as a reinforcement learning engineer at the hottest new non-revenue generating unicorn, MoonShot Technologies (MST). Times are busy at MST, which is preparing for its initial public offering (IPO) at the end of the fiscal year, and your labor is much needed. . Like many successful startups, MST is exceedingly concerned with the valuation that it will receive at its IPO (as this valuation determines the price at which its existing venture capitalist shareholders will be able to sell their shares). Accordingly, to whet the appetites of potential investors, MST has set its sights on accomplishing a technological tour de force &mdash; a lunar landing &mdash; before the year is out. But it is not just any mundane lunar landing that MST aspires toward. Rather than the more sensible approach of employing techniques from aerospace engineering to pilot its spacecraft, MST endeavors to wow investors by training an agent to do the job via reinforcement learning. . However, it is clearly not practical for a reinforcement learning agent to be trained tabula rasa with real rockets &mdash; even the pockets of venture capitalists have their limits. Instead, MST aims to build a simulator that is realistic enough to train an agent that can be deployed in the real world. This will be a difficult project, and will require building a realistic simulator, choosing the right reinforcement learning algorithm, implementing this algorithm, and optimizing the hyperparameters for this algorithm. . Naturally, as the newly hired reinforcement learning engineer, you have been staffed to lead the project. In this notebook, you will take the first steps by building a lunar lander environment. . Creating an Environment . The software engineering team at MST has already set up some infrastructure for your convenience. Specifically, they have provided you with the following functions: . get_velocity - returns an array representing the x, y velocity of the lander. Both the x and y velocity are in the range $[0, 60]$. | . get_angle - returns a scalar representing the angle of the lander. The angle is in the range $[0, 359]$. | . get_position - returns an array representing the x, y position of the lander. Both the x and y position of the agent are in the range $[0, 100]$. | . get_landing_zone - returns an array representing the x, y position of the landing zone. Both the x, y coordinates are in the range $[1, 100]$. | . get_fuel - returns a scalar representing the remaining amount of fuel. Fuel starts at $100$ and is in range $[0, 100]$. | . Note that these are dummy functions just for this assignment. . . In this notebook, you will be applying these functions to structure the reward signal based on the following criteria: . The lander will crash if it touches the ground when y_velocity &lt; -3 (the downward velocity is greater than three). | The lander will crash if it touches the ground when x_velocity &lt; -10 or 10 &lt; x_velocity (horizontal speed is greater than $10$). | The lander&#39;s angle taken values in $[0, 359]$. It is completely vertical at $0$ degrees. The lander will crash if it touches the ground when 5 &lt; angle &lt; 355 (angle differs from vertical by more than $5$ degrees). | The lander will crash if it has yet to land and fuel &lt;= 0 (it runs out of fuel). | MST would like to save money on fuel when it is possible (using less fuel is preferred). | The lander can only land in the landing zone. The lander will crash if it touches the ground when x_position $ not in$ landing_zone (it lands outside the landing zone). | Fill in the methods below to create an environment for the lunar lander. . import environment from utils import get_landing_zone, get_angle, get_velocity, get_position, get_fuel, tests get_landing_zone() # Lunar Lander Environment class LunarLanderEnvironment(environment.BaseEnvironment): def __init__(self): self.current_state = None self.count = 0 def env_init(self, env_info): # users set this up self.state = np.zeros(6) # velocity x, y, angle, distance to ground, landing zone x, y def env_start(self): land_x, land_y = get_landing_zone() # gets the x, y coordinate of the landing zone # At the start we initialize the agent to the top left hand corner (100, 20) with 0 velocity # in either any direction. The agent&#39;s angle is set to 0 and the landing zone is retrieved and set. # The lander starts with fuel of 100. # (vel_x, vel_y, angle, pos_x, pos_y, land_x, land_y, fuel) self.current_state = (0, 0, 0, 100, 20, land_x, land_y, 100) return self.current_state def env_step(self, action): land_x, land_y = get_landing_zone() # gets the x, y coordinate of the landing zone vel_x, vel_y = get_velocity(action) # gets the x, y velocity of the lander angle = get_angle(action) # gets the angle the lander is positioned in pos_x, pos_y = get_position(action) # gets the x, y position of the lander fuel = get_fuel(action) # get the amount of fuel remaining for the lander terminal = False reward = 0.0 observation = (vel_x, vel_y, angle, pos_x, pos_y, land_x, land_y, fuel) # use the above observations to decide what the reward will be, and if the # agent is in a terminal state. # Recall - if the agent crashes or lands terminal needs to be set to True # your code here self.reward_obs_term = (reward, observation, terminal) return self.reward_obs_term def env_cleanup(self): return None def env_message(self): return None . Evaluating your reward function . Designing the best reward function for an objective is a challenging task - it is not clear what the term “best reward function” even means, let alone how to find it. Consequently, rather than evaluating your reward function by quantitative metrics, we merely ask that you check that its behavior is qualitatively reasonable. For this purpose, we provide a series of test cases below. In each case we show a transition and explain how a reward function that we implemented behaves. As you read, check how your own reward behaves in each scenario and judge for yourself whether it acts appropriately. (For the latter parts of the capstone you will use our implementation of the lunar lander environment, so don’t worry if your reward function isn’t exactly the same as ours. The purpose of this of this notebook is to gain experience implementing environments and reward functions.) . Case 1: Uncertain Future . The lander is in the top left corner of the screen moving at a velocity of (12, 15) with 10 units of fuel &mdash; whether this landing will be successful remains to be seen. . . tests(LunarLanderEnvironment, 1) . In this case we gave the agent no reward, as it neither achieved the objective nor crashed. One alternative is giving the agent a positive reward for moving closer to the goal. Another is to give a negative reward for fuel consumption. What did your reward function do? . Also check to make sure that Terminal is set to False. Your agent has not landed, crashed, or ran out of fuel. The episode is not over. . Case 2: Imminent Crash! . The lander is positioned in the target landing zone at a 45 degree angle, but its landing gear can only handle an angular offset of five degrees &mdash; it is about to crash! . . tests(LunarLanderEnvironment, 2) . We gave the agent a reward of -10000 to punish it for crashing. How did your reward function handle the crash? . Also check to make sure that Terminal is set to True. Your agent has crashed and the episode is over. . Case 3: Nice Landing! . The lander is vertically oriented and positioned in the target landing zone with five units of remaining fuel. The landing is being completed successfully! . . tests(LunarLanderEnvironment, 3) . To encourage the agent to conserve as much fuel as possible, we reward successful landings proportionally to the amount of fuel remaining. Here, we gave the agent a reward of five since it landed with five units of fuel remaining. How did you incentivize the agent to be fuel efficient? . Also check to make sure that Terminal is set to True. Your agent has landed and the episode is over. . Case 4: Dark Times Ahead! . The lander is directly above the target landing zone but has no fuel left. The future does not look good for the agent &mdash; without fuel there is no way for it to avoid crashing! . . tests(LunarLanderEnvironment, 4) . We gave the agent a reward of -10000 to punish it for crashing. Did your reward function treat all crashes equally, as ours did? Or did you penalize some crashes more than others? What reasoning did you use to make this decision? . Also check to make sure that Terminal is set to True. Your agent has crashed and the episode is over. . Case 5: Where&#39;s The Landing Zone?! . The lander is touching down at a vertical angle with fuel to spare. But it is not in the landing zone and the surface is uneven &mdash; it is going to crash! . . tests(LunarLanderEnvironment, 5) . We gave the agent a reward of -10000 to punish it for landing in the wrong spot. An alternative is to scale the negative reward by distance from the landing zone. What approach did you take? . Also check to make sure that Terminal is set to True. Your agent has crashed and the episode is over. . Wrapping Up . Excellent! The lunar lander simulator is complete and the project can commence. In the next module, you will build upon your work here by implementing an agent to train in the environment. Don’t dally! The team at MST is eagerly awaiting your solution. .",
            "url": "https://dnlam.github.io/fastblog/2022/03/14/_Moon_Landing_RL_example.html",
            "relUrl": "/2022/03/14/_Moon_Landing_RL_example.html",
            "date": " • Mar 14, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://dnlam.github.io/fastblog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi there, I am Lam DINH (Ngoc-Lam DINH), I graduated from Ha Noi University of Science and Technology (Vietnam) in 2016 with a degree in Electronics and Telecommunications Engineering. My training mainly focused on several areas: Digital Signal Processing, Wireless Communication and Embedded Programming. Then, I continued my study with a special interest in Signal Theory, Wireless Telecommunications and Optical Networks at Universidad Politecnica de Valencia (Spain) in 2017. . My Master’s degree is jointly awarded by the École Normale Supérieure Paris Saclay (France) and the Universidad Complutense de Madrid (Spain) in 2019. The courses are related to the application of molecular photonics to telecommunications and biosensors. . From 2019, I am conducting a PhD thesis at the Commissariat à l’Énergie Atomique (CEA) in Grenoble. My research addresses ultra-reliable and low-latency communications (URLLC) in 5G systems and beyond. . More Information . Personal Web Page .",
          "url": "https://dnlam.github.io/fastblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://dnlam.github.io/fastblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}