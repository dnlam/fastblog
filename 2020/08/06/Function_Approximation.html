<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Deep Reinforcement Learning | Lam Dinh</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Deep Reinforcement Learning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Fifth in a series on understanding Reinforcement Learning." />
<meta property="og:description" content="Fifth in a series on understanding Reinforcement Learning." />
<link rel="canonical" href="https://dnlam.github.io/fastblog/2020/08/06/Function_Approximation.html" />
<meta property="og:url" content="https://dnlam.github.io/fastblog/2020/08/06/Function_Approximation.html" />
<meta property="og:site_name" content="Lam Dinh" />
<meta property="og:image" content="https://www.researchgate.net/publication/333909668/figure/fig1/AS:772039019360256@1561079854431/Schematic-structure-of-deep-reinforcement-learning-agent.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-08-06T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://www.researchgate.net/publication/333909668/figure/fig1/AS:772039019360256@1561079854431/Schematic-structure-of-deep-reinforcement-learning-agent.png" />
<meta property="twitter:title" content="Deep Reinforcement Learning" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-08-06T00:00:00-05:00","datePublished":"2020-08-06T00:00:00-05:00","description":"Fifth in a series on understanding Reinforcement Learning.","headline":"Deep Reinforcement Learning","image":"https://www.researchgate.net/publication/333909668/figure/fig1/AS:772039019360256@1561079854431/Schematic-structure-of-deep-reinforcement-learning-agent.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://dnlam.github.io/fastblog/2020/08/06/Function_Approximation.html"},"url":"https://dnlam.github.io/fastblog/2020/08/06/Function_Approximation.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/fastblog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://dnlam.github.io/fastblog/feed.xml" title="Lam Dinh" /><link rel="shortcut icon" type="image/x-icon" href="/fastblog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/fastblog/">Lam Dinh</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/fastblog/about/">About Me</a><a class="page-link" href="/fastblog/search/">Search</a><a class="page-link" href="/fastblog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Deep Reinforcement Learning</h1><p class="page-description">Fifth in a series on understanding Reinforcement Learning.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-08-06T00:00:00-05:00" itemprop="datePublished">
        Aug 6, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/dnlam/fastblog/tree/master/_notebooks/2020-08-06-Function_Approximation.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/fastblog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/dnlam/fastblog/master?filepath=_notebooks%2F2020-08-06-Function_Approximation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/fastblog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/dnlam/fastblog/blob/master/_notebooks/2020-08-06-Function_Approximation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/fastblog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fdnlam%2Ffastblog%2Fblob%2Fmaster%2F_notebooks%2F2020-08-06-Function_Approximation.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/fastblog/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#Function-approximation-and-deep-reinforcement-learning.">Function approximation and deep reinforcement learning. </a></li>
<li class="toc-entry toc-h1"><a href="#Value-function-approximation">Value function approximation </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Agent-state-update">Agent state update </a></li>
<li class="toc-entry toc-h2"><a href="#Function-classes">Function classes </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-08-06-Function_Approximation.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Function-approximation-and-deep-reinforcement-learning.">
<a class="anchor" href="#Function-approximation-and-deep-reinforcement-learning." aria-hidden="true"><span class="octicon octicon-link"></span></a>Function approximation and deep reinforcement learning.<a class="anchor-link" href="#Function-approximation-and-deep-reinforcement-learning."> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In some senses, the policy, value function , model can be viewed as being a function and we want to learn these functions from experiences.</p>
<p>When we use neural network to represent these functions, then it is often called deep reinforcement learning.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Value-function-approximation">
<a class="anchor" href="#Value-function-approximation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Value function approximation<a class="anchor-link" href="#Value-function-approximation"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So far, we have talked about the tabular case of using look up tabke for every state s (v(s)) or every state-action pair s,a (q(s,a)). However, the problem will be rising if there are too many states and/or actions which can not fit into memory. Besides, it is too slow to learn the value of each state individually. Additionally, individual environment states are often not fully observable.</p>
<p>The solution for all of these problems is to estimate value function with function approximation.
$$
v_w(s) \approx v _\pi(s) \quad \quad \quad \text{or $v_*(s)$} \\
q_w(s,q)  \approx q _\pi(s,a) \quad \quad \quad \text{or $q_*(s,a)$}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, the value function will be parameterized with parameter vector $w$. Then, we will update parameter $w$ using Monte Carlo or TD learning algorithm. With the hope that we are able to select our functions class correctly, we will able to generalize to unseen state.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Agent-state-update">
<a class="anchor" href="#Agent-state-update" aria-hidden="true"><span class="octicon octicon-link"></span></a>Agent state update<a class="anchor-link" href="#Agent-state-update"> </a>
</h2>
<p>When the environment state is not fully observable ($S_t^{env} \neq O_t$), we can use parameterized agent state.
$$
s_t = u_w (s_{t-1}, A_{t-1}, O_t)
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, we will rely on agent state instead and we are going to use agent state update function which is a parametric function of its inputs (previous agent states, action and observation).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Function-classes">
<a class="anchor" href="#Function-classes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Function classes<a class="anchor-link" href="#Function-classes"> </a>
</h2>
<p>We have several classes of function approximation:</p>
<ul>
<li>Tabular: is a table with an entry for each MDP state</li>
<li>State aggregation: we have entries that merge the values of a couple of states (grouping state spaces into some small set). </li>
<li>Linear function approximation: We consider a fixed agent state update function and fixed feature map on top of that. The linear function here is because of value functions do not have any parameters. Instead, we are going to learn the parameters of the value functions which uses thoese features as inputs $ v_w(s) = w^T x(s)$. Then, state aggregation and tabular case are special cases of linear FA.</li>
<li>Differentiable function approximation: oue value function will be a differential function of parameter $w$ which could be non linear. </li>
</ul>
<p>In principle, any function approximator can be used, but RL has several special properties:</p>
<ul>
<li>Experience is not i.i.d which means that successive time steps are correlated. </li>
<li>Agent's policy affects the data it receives which means that we can actively sample data in a way that is useful for learning our function.</li>
<li>Regression targets can be non-stationary because of changing policies  as we go but it might change the target and the data and because of bootstraping. </li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="dnlam/fastblog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/fastblog/2020/08/06/Function_Approximation.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/fastblog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/fastblog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/fastblog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My blog about code and ideas.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/dnlam" target="_blank" title="dnlam"><svg class="svg-icon grey"><use xlink:href="/fastblog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/lam-dinh-34a66a160" target="_blank" title="lam-dinh-34a66a160"><svg class="svg-icon grey"><use xlink:href="/fastblog/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
