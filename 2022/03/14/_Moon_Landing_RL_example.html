<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>MoonShot Technologies | Lam Dinh</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="MoonShot Technologies" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My blog about code and ideas." />
<meta property="og:description" content="My blog about code and ideas." />
<link rel="canonical" href="https://dnlam.github.io/fastblog/2022/03/14/_Moon_Landing_RL_example.html" />
<meta property="og:url" content="https://dnlam.github.io/fastblog/2022/03/14/_Moon_Landing_RL_example.html" />
<meta property="og:site_name" content="Lam Dinh" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-03-14T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="MoonShot Technologies" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-03-14T00:00:00-05:00","datePublished":"2022-03-14T00:00:00-05:00","description":"My blog about code and ideas.","headline":"MoonShot Technologies","mainEntityOfPage":{"@type":"WebPage","@id":"https://dnlam.github.io/fastblog/2022/03/14/_Moon_Landing_RL_example.html"},"url":"https://dnlam.github.io/fastblog/2022/03/14/_Moon_Landing_RL_example.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/fastblog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://dnlam.github.io/fastblog/feed.xml" title="Lam Dinh" /><link rel="shortcut icon" type="image/x-icon" href="/fastblog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/fastblog/">Lam Dinh</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/fastblog/about/">About Me</a><a class="page-link" href="/fastblog/search/">Search</a><a class="page-link" href="/fastblog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">MoonShot Technologies</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-03-14T00:00:00-05:00" itemprop="datePublished">
        Mar 14, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/dnlam/fastblog/tree/master/_notebooks/2022-03-15_Moon_Landing_RL_example.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/fastblog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/dnlam/fastblog/master?filepath=_notebooks%2F2022-03-15_Moon_Landing_RL_example.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/fastblog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/dnlam/fastblog/blob/master/_notebooks/2022-03-15_Moon_Landing_RL_example.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/fastblog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fdnlam%2Ffastblog%2Fblob%2Fmaster%2F_notebooks%2F2022-03-15_Moon_Landing_RL_example.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/fastblog/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-03-15_Moon_Landing_RL_example.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Congratulations! Due to your strong performance in the first three courses, you landed a job as a reinforcement learning engineer at the hottest new non-revenue generating unicorn, MoonShot Technologies (MST). Times are busy at MST, which is preparing for its initial public offering (IPO) at the end of the fiscal year, and your labor is much needed.</p>
<p>Like many successful startups, MST is exceedingly concerned with the valuation that it will receive at its IPO (as this valuation determines the price at which its existing venture capitalist shareholders will be able to sell their shares). Accordingly, to whet the appetites of potential investors, MST has set its sights on accomplishing a technological tour de force &mdash; a lunar landing &mdash; before the year is out. But it is not just any mundane lunar landing that MST aspires toward. Rather than the more sensible approach of employing techniques from aerospace engineering to pilot its spacecraft, MST endeavors to wow investors by training an agent to do the job via reinforcement learning.</p>
<p>However, it is clearly not practical for a reinforcement learning agent to be trained tabula rasa with real rockets &mdash; even the pockets of venture capitalists have their limits. Instead, MST aims to build a simulator that is realistic enough to train an agent that can be deployed in the real world. This will be a difficult project, and will require building a realistic simulator, choosing the right reinforcement learning algorithm, implementing this algorithm, and optimizing the hyperparameters for this algorithm.</p>
<p>Naturally, as the newly hired reinforcement learning engineer, you have been staffed to lead the project. In this notebook, you will take the first steps by building a lunar lander environment.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creating-an-Environment">Creating an Environment<a class="anchor-link" href="#Creating-an-Environment"> </a></h2><p>The software engineering team at MST has already set up some infrastructure for your convenience. Specifically, they have provided you with the following functions:</p>
<ul>
<li><strong>get_velocity</strong> - returns an array representing the x, y velocity of the lander. Both the x and y velocity are in the range $[0, 60]$.</li>
</ul>
<ul>
<li><strong>get_angle</strong> - returns a scalar representing the angle of the lander. The angle is in the range $[0, 359]$.</li>
</ul>
<ul>
<li><strong>get_position</strong> - returns an array representing the x, y position of the lander. Both the x and y position of the agent are in the range $[0, 100]$.</li>
</ul>
<ul>
<li><strong>get_landing_zone</strong> - returns an array representing the x, y position of the landing zone. Both the x, y coordinates are in the range $[1, 100]$. </li>
</ul>
<ul>
<li><strong>get_fuel</strong> - returns a scalar representing the remaining amount of fuel. Fuel starts at $100$ and is in range $[0, 100]$.</li>
</ul>
<p>Note that these are dummy functions just for this assignment.</p>
<p><img src="/fastblog/images/copied_from_nb/lunar_landar.png" alt="Lunar Landar" /></p>
<p>In this notebook, you will be applying these functions to <strong>structure the reward signal</strong> based on the following criteria:</p>
<ol>
<li><strong>The lander will crash if</strong> it touches the ground when <code>y_velocity &lt; -3</code> (the downward velocity is greater than three).</li>
</ol>
<ol>
<li><strong>The lander will crash if</strong> it touches the ground when <code>x_velocity &lt; -10 or 10 &lt; x_velocity</code> (horizontal speed is greater than $10$).</li>
</ol>
<ol>
<li>The lander's angle taken values in $[0, 359]$. It is completely vertical at $0$ degrees. <strong>The lander will crash if</strong> it touches the ground when <code>5 &lt; angle &lt; 355</code> (angle differs from vertical by more than $5$ degrees).</li>
</ol>
<ol>
<li><strong>The lander will crash if</strong> it has yet to land and <code>fuel &lt;= 0</code> (it runs out of fuel).</li>
</ol>
<ol>
<li>MST would like to save money on fuel when it is possible <strong>(using less fuel is preferred)</strong>.</li>
</ol>
<ol>
<li>The lander can only land in the landing zone. <strong>The lander will crash if</strong> it touches the ground when <code>x_position</code> $\not\in$ <code>landing_zone</code> (it lands outside the landing zone).</li>
</ol>
<p>Fill in the methods below to create an environment for the lunar lander.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">environment</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">get_landing_zone</span><span class="p">,</span> <span class="n">get_angle</span><span class="p">,</span> <span class="n">get_velocity</span><span class="p">,</span> <span class="n">get_position</span><span class="p">,</span> <span class="n">get_fuel</span><span class="p">,</span> <span class="n">tests</span>
<span class="n">get_landing_zone</span><span class="p">()</span>
<span class="c1"># Lunar Lander Environment</span>
<span class="k">class</span> <span class="nc">LunarLanderEnvironment</span><span class="p">(</span><span class="n">environment</span><span class="o">.</span><span class="n">BaseEnvironment</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">def</span> <span class="nf">env_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_info</span><span class="p">):</span>
        <span class="c1"># users set this up</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span> <span class="c1"># velocity x, y, angle, distance to ground, landing zone x, y</span>
    
    <span class="k">def</span> <span class="nf">env_start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">land_x</span><span class="p">,</span> <span class="n">land_y</span> <span class="o">=</span> <span class="n">get_landing_zone</span><span class="p">()</span> <span class="c1"># gets the x, y coordinate of the landing zone</span>
        <span class="c1"># At the start we initialize the agent to the top left hand corner (100, 20) with 0 velocity </span>
        <span class="c1"># in either any direction. The agent&#39;s angle is set to 0 and the landing zone is retrieved and set.</span>
        <span class="c1"># The lander starts with fuel of 100.</span>
        <span class="c1"># (vel_x, vel_y, angle, pos_x, pos_y, land_x, land_y, fuel)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">land_x</span><span class="p">,</span> <span class="n">land_y</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span>
    
    <span class="k">def</span> <span class="nf">env_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        
        <span class="n">land_x</span><span class="p">,</span> <span class="n">land_y</span> <span class="o">=</span> <span class="n">get_landing_zone</span><span class="p">()</span> <span class="c1"># gets the x, y coordinate of the landing zone</span>
        <span class="n">vel_x</span><span class="p">,</span> <span class="n">vel_y</span> <span class="o">=</span> <span class="n">get_velocity</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># gets the x, y velocity of the lander</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="n">get_angle</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># gets the angle the lander is positioned in</span>
        <span class="n">pos_x</span><span class="p">,</span> <span class="n">pos_y</span> <span class="o">=</span> <span class="n">get_position</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># gets the x, y position of the lander</span>
        <span class="n">fuel</span> <span class="o">=</span> <span class="n">get_fuel</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># get the amount of fuel remaining for the lander</span>
        
        <span class="n">terminal</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="p">(</span><span class="n">vel_x</span><span class="p">,</span> <span class="n">vel_y</span><span class="p">,</span> <span class="n">angle</span><span class="p">,</span> <span class="n">pos_x</span><span class="p">,</span> <span class="n">pos_y</span><span class="p">,</span> <span class="n">land_x</span><span class="p">,</span> <span class="n">land_y</span><span class="p">,</span> <span class="n">fuel</span><span class="p">)</span>
        
        <span class="c1"># use the above observations to decide what the reward will be, and if the</span>
        <span class="c1"># agent is in a terminal state.</span>
        <span class="c1"># Recall - if the agent crashes or lands terminal needs to be set to True</span>
        
        <span class="c1"># your code here</span>
        
        
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_obs_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="n">observation</span><span class="p">,</span> <span class="n">terminal</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_obs_term</span>
    
    <span class="k">def</span> <span class="nf">env_cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>
    
    <span class="k">def</span> <span class="nf">env_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluating-your-reward-function">Evaluating your reward function<a class="anchor-link" href="#Evaluating-your-reward-function"> </a></h2><p>Designing the best reward function for an objective is a challenging task - it is not clear what the term “best reward function” even means, let alone how to find it. Consequently, rather than evaluating your reward function by quantitative metrics, we merely ask that you check that its behavior is qualitatively reasonable. For this purpose, we provide a series of test cases below. In each case we show a transition and explain how a reward function that we implemented behaves. As you read, check how your own reward behaves in each scenario and judge for yourself whether it acts appropriately. (For the latter parts of the capstone you will use our implementation of the lunar lander environment, so don’t worry if your reward function isn’t exactly the same as ours. The purpose of this of this notebook is to gain experience implementing environments and reward functions.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Case-1:-Uncertain-Future">Case 1: Uncertain Future<a class="anchor-link" href="#Case-1:-Uncertain-Future"> </a></h3><p>The lander is in the top left corner of the screen moving at a velocity of (12, 15) with 10 units of fuel &mdash; whether this landing will be successful remains to be seen.</p>
<p><img src="/fastblog/images/copied_from_nb/lunar_landar_1.png" alt="Lunar Landar" /></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tests</span><span class="p">(</span><span class="n">LunarLanderEnvironment</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this case we gave the agent no reward, as it neither achieved the objective nor crashed. One alternative is giving the agent a positive reward for moving closer to the goal. Another is to give a negative reward for fuel consumption. What did your reward function do?</p>
<p>Also check to make sure that <code>Terminal</code> is set to <code>False</code>. Your agent has not landed, crashed, or ran out of fuel. The episode is not over.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Case-2:-Imminent-Crash!">Case 2: Imminent Crash!<a class="anchor-link" href="#Case-2:-Imminent-Crash!"> </a></h3><p>The lander is positioned in the target landing zone at a 45 degree angle, but its landing gear can only handle an angular offset of five degrees &mdash; it is about to crash!</p>
<p><img src="/fastblog/images/copied_from_nb/lunar_landar_2.png" alt="Lunar Landar" /></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tests</span><span class="p">(</span><span class="n">LunarLanderEnvironment</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We gave the agent a reward of -10000 to punish it for crashing. How did your reward function handle the crash?</p>
<p>Also check to make sure that <code>Terminal</code> is set to <code>True</code>. Your agent has crashed and the episode is over.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Case-3:-Nice-Landing!">Case 3: Nice Landing!<a class="anchor-link" href="#Case-3:-Nice-Landing!"> </a></h3><p>The lander is vertically oriented and positioned in the target landing zone with five units of remaining fuel. The landing is being completed successfully!</p>
<p><img src="/fastblog/images/copied_from_nb/lunar_landar_3.png" alt="Lunar Landar" /></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tests</span><span class="p">(</span><span class="n">LunarLanderEnvironment</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To encourage the agent to conserve as much fuel as possible, we reward successful landings proportionally to the amount of fuel remaining. Here, we gave the agent a reward of five since it landed with five units of fuel remaining. How did you incentivize the agent to be fuel efficient?</p>
<p>Also check to make sure that <code>Terminal</code> is set to <code>True</code>. Your agent has landed and the episode is over.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Case-4:-Dark-Times-Ahead!">Case 4: Dark Times Ahead!<a class="anchor-link" href="#Case-4:-Dark-Times-Ahead!"> </a></h3><p>The lander is directly above the target landing zone but has no fuel left. The future does not look good for the agent &mdash; without fuel there is no way for it to avoid crashing!</p>
<p><img src="/fastblog/images/copied_from_nb/lunar_landar_4.png" alt="Lunar Landar" /></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tests</span><span class="p">(</span><span class="n">LunarLanderEnvironment</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We gave the agent a reward of -10000 to punish it for crashing. Did your reward function treat all crashes equally, as ours did? Or did you penalize some crashes more than others? What reasoning did you use to make this decision?</p>
<p>Also check to make sure that <code>Terminal</code> is set to <code>True</code>. Your agent has crashed and the episode is over.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Case-5:-Where's-The-Landing-Zone?!">Case 5: Where's The Landing Zone?!<a class="anchor-link" href="#Case-5:-Where's-The-Landing-Zone?!"> </a></h3><p>The lander is touching down at a vertical angle with fuel to spare. But it is not in the landing zone and the surface is uneven &mdash; it is going to crash!</p>
<p><img src="/fastblog/images/copied_from_nb/lunar_landar_5.png" alt="Lunar Landar" /></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tests</span><span class="p">(</span><span class="n">LunarLanderEnvironment</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We gave the agent a reward of -10000 to punish it for landing in the wrong spot. An alternative is to scale the negative reward by distance from the landing zone. What approach did you take?</p>
<p>Also check to make sure that <code>Terminal</code> is set to <code>True</code>. Your agent has crashed and the episode is over.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Wrapping-Up">Wrapping Up<a class="anchor-link" href="#Wrapping-Up"> </a></h2><p>Excellent! The lunar lander simulator is complete and the project can commence. In the next module, you will build upon your work here by implementing an agent to train in the environment. Don’t dally! The team at MST is eagerly awaiting your solution.</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/fastblog/2022/03/14/_Moon_Landing_RL_example.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/fastblog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/fastblog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/fastblog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My blog about code and ideas.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/dnlam" target="_blank" title="dnlam"><svg class="svg-icon grey"><use xlink:href="/fastblog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/lam-dinh-34a66a160" target="_blank" title="lam-dinh-34a66a160"><svg class="svg-icon grey"><use xlink:href="/fastblog/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
